{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "df = pd.read_csv(‘Dataset.csv’)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "output: (50000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(1000)\n",
    "# resetting index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# sample dataset size\n",
    "df.shape\n",
    "output: (1000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[‘sentiment’].replace({‘positive’:1, ‘negative’:0}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(text):\n",
    " clean = re.compile(‘<.*?>’)\n",
    " return re.sub(clean, ‘’, text)\n",
    "# remove brackets\n",
    "def remove_brackets(text):\n",
    " return re.sub(‘\\[[^]]*\\]’, ‘’, text)\n",
    "# lower the cases\n",
    "def lower_cases(text):\n",
    " return text.lower()\n",
    "# remove special characters\n",
    "def remove_char(text):\n",
    " pattern = r’[^a-zA-z0–9\\s]’\n",
    " text = re.sub(pattern, ‘’, text)\n",
    " return text\n",
    "# remove noise(combine above functions)\n",
    "def remove_noise(text):\n",
    " text = clean_html(text)\n",
    " text = remove_brackets(text)\n",
    " text = lower_cases(text) \n",
    " text = remove_char(text) \n",
    " return text\n",
    "# call the function on predictors\n",
    "df['review']=df['review'].apply(remove_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "def stem_words(text):\n",
    " ps = PorterStemmer()\n",
    " stem_list = [ps.stem(word) for word in text.split()] \n",
    " text = ‘’.join(ps.stem(word) for word in text)\n",
    " \n",
    " return text\n",
    "df[‘review’] = df[‘review’].apply(stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing from nlptoolkit library\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# creating list of english stopwords\n",
    "stopword_list = stopwords.words(‘english’)\n",
    "# removing the stopwords from review\n",
    "def remove_stopwords(text):\n",
    "    # list to add filtered words from review\n",
    "    filtered_text = []\n",
    "        # verify & append words from the text to filtered_text list\n",
    "        for word in text.split():\n",
    "            if word not in stopword_list:\n",
    "                filtered_text.append(word)\n",
    "        # add content from filtered_text list to new variable\n",
    "        clean_review = filtered_text[:]\n",
    "        # emptying the filtered_text list for new review\n",
    "        filtered_text.clear()\n",
    "        return clean_review\n",
    "df['review']=df['review'].apply(remove_stopwords)\n",
    "df['review']\n",
    "# join back all words as single paragraph\n",
    "def join_back(text):\n",
    "    return ' '.join(text)\n",
    "df['review'] = df['review'].apply(join_back)\n",
    "# check if changes are applied\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=800)\n",
    "# vectorizing words and storing in variable X(predictor)\n",
    "X = cv.fit_transform(df[‘review’]).toarray()\n",
    "# predictor\n",
    "X\n",
    "# X size\n",
    "X.shape\n",
    "output: (1000, 800)\n",
    "# target\n",
    "y = df.iloc[:,-1].values\n",
    "# y size\n",
    "y.shape\n",
    "output: (1000, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Naive Bayes Classifiers\n",
    "gnb = GaussianNB()\n",
    "mnb = MultinomialNB()\n",
    "bnb = BernoulliNB()\n",
    "# fitting and predicting\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "mnb.fit(X_train, y_train)\n",
    "y_pred_mnb = mnb.predict(X_test)\n",
    "bnb.fit(X_train, y_train)\n",
    "y_pred_bnb = bnb.predict(X_test)\n",
    "# accuracy scores\n",
    "print(\"Gaussian\", accuracy_score(y_test, y_pred_gnb))\n",
    "print(\"Multinomial\", accuracy_score(y_test, y_pred_mnb))\n",
    "print(\"Bernoulli\", accuracy_score(y_test, y_pred_bnb))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
