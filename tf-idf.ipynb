{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import string\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc1 = \"Natural Language Toolkit (NLTK) is a powerful library in Python for natural language processing tasks.\"\n",
    "Doc2 = \"With NLTK, you can tokenize text, perform stemming, lemmatization, and much more to preprocess your data.\"\n",
    "Doc3 = \"One of NLTK's key features is its extensive collection of corpora and lexical resources for training and testing NLP models.\"\n",
    "Doc4 = \"NLTK provides easy-to-use interfaces to perform sentiment analysis, part-of-speech tagging, and named entity recognition.\"\n",
    "Doc5 = \"By leveraging NLTK's functionalities, implementing TF-IDF for text analysis becomes straightforward, allowing you to extract important features from your corpus.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural Language Toolkit (NLTK) is a powerful library in Python for natural language processing tasks.',\n",
       " 'With NLTK, you can tokenize text, perform stemming, lemmatization, and much more to preprocess your data.',\n",
       " \"One of NLTK's key features is its extensive collection of corpora and lexical resources for training and testing NLP models.\",\n",
       " 'NLTK provides easy-to-use interfaces to perform sentiment analysis, part-of-speech tagging, and named entity recognition.',\n",
       " \"By leveraging NLTK's functionalities, implementing TF-IDF for text analysis becomes straightforward, allowing you to extract important features from your corpus.\"]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus = [Doc1,Doc2,Doc3,Doc4,Doc5]\n",
    "total_doc_num = len(Corpus)\n",
    "Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "global_tf_corpus = []\n",
    "word_frequencies = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in Corpus:\n",
    "    tokens = word_tokenize(each)\n",
    "    filtered_tokens = [word.lower() for word in tokens if word.lower() not in stop_words and word.lower() not in string.punctuation]\n",
    "    word_freq = Counter(filtered_tokens)\n",
    "    word_corpus = dict(word_freq)\n",
    "    length = len(filtered_tokens)\n",
    "    global_tf_corpus.append({key: value / length for key, value in word_corpus.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(word_frequencies):\n",
    "    idf_values = {}\n",
    "    for word, freq in word_frequencies.items():\n",
    "        idf_values[word] = math.log(total_doc_num/freq)\n",
    "    return idf_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_set in global_tf_corpus:\n",
    "    for word in doc_set:\n",
    "        if word in word_frequencies:\n",
    "            word_frequencies[word] += 1\n",
    "        else:\n",
    "            word_frequencies[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_values = idf(word_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_scores = []\n",
    "\n",
    "for tf_doc in global_tf_corpus:\n",
    "    tfidf_doc = {}\n",
    "    for term, tf in tf_doc.items():\n",
    "        tfidf_doc[term] = tf * idf_values[term]\n",
    "    tfidf_scores.append(tfidf_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'natural': 0.29262507498801826, 'language': 0.29262507498801826, 'toolkit': 0.14631253749400913, 'nltk': 0.0, 'powerful': 0.14631253749400913, 'library': 0.14631253749400913, 'python': 0.14631253749400913, 'processing': 0.14631253749400913, 'tasks': 0.14631253749400913}\n",
      "{'nltk': 0.0, 'tokenize': 0.17882643471490003, 'text': 0.10181008131935056, 'perform': 0.10181008131935056, 'stemming': 0.17882643471490003, 'lemmatization': 0.17882643471490003, 'much': 0.17882643471490003, 'preprocess': 0.17882643471490003, 'data': 0.17882643471490003}\n",
      "{'one': 0.11495985088815001, 'nltk': 0.0, \"'s\": 0.06544933799101108, 'key': 0.11495985088815001, 'features': 0.06544933799101108, 'extensive': 0.11495985088815001, 'collection': 0.11495985088815001, 'corpora': 0.11495985088815001, 'lexical': 0.11495985088815001, 'resources': 0.11495985088815001, 'training': 0.11495985088815001, 'testing': 0.11495985088815001, 'nlp': 0.11495985088815001, 'models': 0.11495985088815001}\n",
      "{'nltk': 0.0, 'provides': 0.134119826036175, 'easy-to-use': 0.134119826036175, 'interfaces': 0.134119826036175, 'perform': 0.07635756098951292, 'sentiment': 0.134119826036175, 'analysis': 0.07635756098951292, 'part-of-speech': 0.134119826036175, 'tagging': 0.134119826036175, 'named': 0.134119826036175, 'entity': 0.134119826036175, 'recognition': 0.134119826036175}\n",
      "{'leveraging': 0.10729586082894002, 'nltk': 0.0, \"'s\": 0.06108604879161034, 'functionalities': 0.10729586082894002, 'implementing': 0.10729586082894002, 'tf-idf': 0.10729586082894002, 'text': 0.06108604879161034, 'analysis': 0.06108604879161034, 'becomes': 0.10729586082894002, 'straightforward': 0.10729586082894002, 'allowing': 0.10729586082894002, 'extract': 0.10729586082894002, 'important': 0.10729586082894002, 'features': 0.06108604879161034, 'corpus': 0.10729586082894002}\n"
     ]
    }
   ],
   "source": [
    "for each in tfidf_scores:\n",
    "    print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
